# 多线程并发安全原理

### 初识volatile

#### 什么是volatile？他能干嘛？

&emsp;&emsp;它是一个类型修饰符，也是一个指令关键字；它可以使得在多处理器环境下保证了共享变量的可见性。

`volatile` 会在生成的字节码中加入一条`lock`指令，这个指令有两个作用：

1. 将当前处理器缓存写回到内存
2. 使其它线程的cpu缓存失效

#### 什么是可见性？

&emsp;&emsp;在多线程环境下，读和写发生在不同的线程中的时候，可能会出现读线程不能及时的读取到其他线程写入的最新数据，这就是所谓的可见性。为了实现线程写入的内存可见性，必须使用某种机制来实现，而volatile就是其中的一种方式。

#### volatile是如何保证可见性的？

&emsp;&emsp;先来看下`volatile`是如何使用的。

#### volatile的使用

```java
public class VolatileDemo {

    private static volatile VolatileDemo instance = null;

    public static VolatileDemo getInstance(){
        if (instance == null){
            instance = new VolatileDemo();
        }
        return instance;
    }

    public static void main(String[] args) {
        VolatileDemo.getInstance();
    }
}
```

&emsp;&emsp;在运行的代码中，设置jvm参数如下：

```
-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*VolatileDemo.getInstance
```

通过配置后运行代码 可以看到如下一部分汇编指令：

```
0x0000000110f1fedb: lock addl $0x0,(%rsp)     ;*putstatic instance
                                                ; - com.thread.threaddemo.VolatileDemo::getInstance@13 (line 9)

```

从上述可以发现，在修改带有volatile修饰的成员变量时，会多一个lock指令。

lock是一种控制指令，在多处理器环境下，lock汇编指令可以基于总线锁或者缓存锁的机制来达到可见性的效果。

### 从硬件层面了解可见性的本质

一台计算机中最核心的组件是cpu、内存、以及I/O设备。在整个计算机的发展历程中，除了cpu、内存以及I/O设备在不断迭代升级来提升计算机处理性能之外，还有一个非常核心的矛盾点，就是这三者在处理速度的差异。cpu的计算速度是非常快的，内存次之，最后是IO设备比如磁盘。而在绝大部分的程序中，一定会存在内存访问，有些可能还会存在I/O设备的访问，为了提升计算性能，cpu从单核升级到了多核甚至用到了[超线程技术]([https://baike.baidu.com/item/%E8%B6%85%E7%BA%BF%E7%A8%8B/86034?fromtitle=%E8%B6%85%E7%BA%BF%E7%A8%8B%E6%8A%80%E6%9C%AF&fromid=276864&fr=aladdin](https://baike.baidu.com/item/超线程/86034?fromtitle=超线程技术&fromid=276864&fr=aladdin))最大化提高cpu的处理性能，但是仅仅提升cpu性能还不够，如果后面两者的处理性能没有跟上，意味着整体的计算效率取决于最慢的设备。为了平衡三者的速度差异，最大化的利用cpu提升性能，从硬件、操作系统、编译器等方面都做出了很多的优化：

1、cpu增加了高速缓存

2、操作系统增加了进程、线程。通过cpu的时间片切换最大化的提升cpu的使用率

3、编译器的指令优化，更合理的去利用好cpu的高速缓存

然后每一种优化，都会带来相应的问题，而这些问题也是导致线程安全性问题的根源。

### 优化过程

#### cpu高速缓存

线程是cpu调度的最小单元，线程设计的目的最终仍然是更充分的利用计算机处理的效能，但是绝大部分的运算任务不能依靠处理器计算就能完成，处理器还需要与内存交互，比如读取运算数据、内存运算结果，这个I/O操作是很难消除的。而由于计算机的存储设备与处理器的运算速度差距非常大，所以现代计算机系统都会增加一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存和处理器之间的缓存：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中。

![image](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/cpu高速缓存.png)

通过高速缓存的存储交互很好的解决了处理器与内存的速度问题，但是也为计算机系统带来了更高的复杂度，因为它引入了一个新的问题，**缓存一致性**。

#### 什么是缓存一致性？

首先，有了高速缓存的存在以后，每个cpu的处理过程是，先将计算需要用到的数据缓存在cpu高速缓存中，在cpu进行计算时，直接从高速缓存中读取数据并且在计算完成之后写入到缓存中。在整个运算过程完成后，再把缓存中的数据同步到主内存。

由于在多cpu中，每个线程可能会运行在不同的cpu内，并且每个线程拥有自己的高速缓存，同一份数据可能会被缓存到多个cpu中，如果在不同cpu中运行的不同线程，看到同一份内存的缓存值不一样就会存在缓存不一致的问题。

为了解决缓存不一致的问题，在cpu层面做了很多事情，主要提供了两种解决方法：总线锁、缓存锁

##### 总线锁

在多cpu下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个LOCK#信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据，总线锁定把cpu和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁的开销比较大，这种机制显然不理想。

​		如何优化呢？最好的方法就是控制锁的粒度，我们只需要保证对于被多个cpu缓存的同一份数据是一致的就可以。所以引入了缓存锁，它核心机制是基于缓存一致性协议来实现的。

##### 缓存一致性协议

​		为了达到数据访问的一致，需要各个处理器在访问缓存时遵循一些协议，在读写时根据协议来操作，常见的协议有MSI、MESI、MOSI等。最常见的就是MESI协议。

##### MESI 协议表示缓存行的四种状态：

1、M(Modify)表示该缓存行只被缓存在该cpu的缓存中，并且是被修改过的，即与主内存中的数据不一致，该缓存行中的内存需要再未来的某个时间点(其它cpu拉取主内存之前)写回主内存。当被写回主内存之后，该缓存行的状态会变成独享状态(Exclusive)。

2、E(Exclusive)表示缓存的独占状态，数据只缓存在当前cpu缓存中，并且没有被修改，与主内存中数据一致；该状态可以在任何时刻，当有其他cpu读取该内存时变成共享状态(Shared)，同样，当cpu修改该缓存行中内容时，该状态可以变成Modify状态

3、S(Shared)表示数据可能被多个cpu缓存，并且各个缓存中的数据和主内存数据一致

4、I(Invalid)表示缓存已经失效

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/MESI协议.png)

对于MESi协议，从cpu读写角度来说会遵循以下原则：

**cpu读请求：**缓存处于M、E、S状态都可以被读取，I状态cpu只能从主内存中读取数据

**cpu写请求：**缓存处于M、E状态才可以被写，对于S状态的写，需要将其他cpu中缓存行置为无效才可以写

使用总线锁和缓存锁达到缓存一致性效果图：

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/缓存一致性总结.png)

##### 思考：

​     基于缓存一致性协议或者总线锁能够达到缓存一致性的要求，为什么还要加volatile关键字？

#### MESI协议优化带来的可见性问题

​     ![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/MESI带来的问题.png)

当cpu0写数据后，通知其他cpu的缓存失效的这个过程是阻塞状态的，同时会带来资源的浪费，为了避免这个问题，在cpu中引入了store bufferes，cpu只需要在写入共享数据时，直接把数据写入到store bufferes中，同时发送invalidate消息，然后继续去处理其他指令；当收到其他所有cpu发送了invalidate ack消息时，再将store bufferes中的数据存储至cache中，最后再从缓存行同步到主内存。

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/cpu引入store bufferes.png)

虽然解决了阻塞问题，但是这种优化会存在问题：

1、数据提交时机无法确定，因为他需要等待其他cpu返回ack才会进行数据同步（异步操作）

2、引入了store bufferes后，处理器会先尝试从storebufferes中读取值，如果storebuffere中有数据，则直接从storebuffere中读取，否则就从缓存行中读取

##### 举个栗子

```
public class ReorderDemo {

    private boolean flag = false;
    private int value = 0;

    private void doCpu0() {
        value = 10;//①
        flag = true;//②
    }

    private void doCpu1() {
        if (flag) {//③
            assert value == 10;
        }
    }
}
```

上述代码最终的出来的结果value不一定等于10，原因是①和②是异步的，导致cpu1收到的消息②先于①；这种现象咱们可以认为是一种重排序，而这种重排序会带来可见性的问题。

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/软硬件工程师对话.png)

经过硬件和软件的沟通，他们决定在cpu层面提供了memory barrier（内存屏障）的指令，从硬件层面来看这个内存屏障就是cpu flush store bufferes中的指令；从软件层面可以决定在适当的地方来插入内存屏障。

#### cpu层面的内存屏障

##### 什么是内存屏障

​     是将store bufferes中的指令写入到内存，从而使得其他访问同一共享内存的线程的可见性。

​     内存屏障包括：lfence（读屏障）；sfence（写屏障）mfence（全屏障）

###### Store Memory Barrier（写屏障）

​		告诉处理器在写屏障之前，所有已经存储在store bufferes中的数据同步到主内存；

###### Load Memory Barrier（读屏障）

​		告诉处理器在读屏障之后，让store bufferes中的数据失效，强制从主内存加载数据；

###### Full Memory Barrier（全屏障）

​		确保屏障前的内存读写操作的结果提交到内存之后，再执行屏障后的读写操作

###### 举个栗子

```
public class ReorderDemo {

    private boolean flag = false;
    private int value = 0;

    private void doCpu0() {
        value = 10;//①
        storeMemoryBarrier();
        flag = true;//②
    }

    private void doCpu1() {
        if (flag) {//③
            loadMemoryBarrier();
            assert value == 10;
        }
    }
}
```

##### 总结

​	内存屏障的作用可以防止cpu对内存的乱序访问，从而来保证共享数据在多线程并行执行下的可见性

#### JMM

##### 什么是JMM？

​		JMM全称是Java Memory Model。它提供了合理的禁用缓存和禁止重排序的方法，主要是为了解决可见性和有序性。

​		JMM属于语言级别的抽象内存模型，可以简单理解为对硬件模型的抽象，它定义了共享内存中多线程程序读写操作的行为规范，在虚拟机中把共享变量存储到内存以及从内存中读取共享变量的底层实现细节，他解决了cpu多级缓存、处理器优化、指令重排序导致的内存访问问题，以及并发场景下的可见性

##### JMM原理

​		JMM抽象模型分为主内存、工作内存；

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/JMM模型.png)

###### JMM是如何解决可见性有序性问题的

​	简单来说，JMM提供 了一些禁用缓存以及禁止重排序的方法，来解决可见性和有序性问题。常见的方法有：volatile、synchronized、final

###### 重排序问题

​		为了提高程序的执行性能，编译器和处理器都会对指令做重排序；

从源代码到最终执行的指令，可能会经过三种重排序：

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/重排序过程.png)

​		编译器的重排序：就是程序编写的代码在编译之后，代码可能会产生重排序来优化程序的执行性能，它禁止了特定类型的编译器重排序

​		处理器的重排序：JMM会要求编译器生成指令时，会插入内存屏障来禁止处理器重排序

###### JMM层面的内存屏障

​		为了保证内存可见性，java编译器在生成指令序列的适当位置会插入内存屏障来禁止特定类型的处理器的重排序，在JMM中把内存屏障分为四类：

| 屏障类型            | 指令实例                     | 备注                                                         |
| ------------------- | ---------------------------- | ------------------------------------------------------------ |
| LoadLoad Barriers   | Load1；LoadLoad；Load2       | 确保load1数据的装载优先于load2及所有后续装载指令的装载       |
| StoreStore Barriers | Store1；StoreStore；Store2； | 确保store1数据对其他处理器可见优先于store2及所有后续存储指令的存储 |
| LoadStore Barriers  | Load1；LoadStore；Store2；   | 确保load1数据装载优先于store2以及后续的存储指令刷新到内存    |
| StoreLoad Barriers  | Store1；StoreLoad；Load；    | 确保store1数据对其他处理器变得可见，优先于load2及所有后续装载指令的装载；这条内存屏障指令是一个全能型的屏障 |

##### HappenBefore

​	它是前一个操作的结果对于后续操作是可见的，所以它是一种表达多个线程之间对于内存的可见性；因此，我们可以认为在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before关系，这两个操作可以是同一个线程，也可以是不同的线程。

###### JMM中有哪些方法建立了happen-before规则

1、程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作，可以简单认为是as-if-serial语义（编译器和处理器不会对存在数据依赖关系的操作做重排序）

单个线程中的代码顺序不管怎么变，对于结果来说是不变的，顺序规则表示：① happens-before ②； ③ happens-before ④

```
public class JMMDemo {
    int a = 0;
    volatile boolean flag = false;

    public void writer() {
        a = 1;//①
        flag = true;//②
    }

    public void reader() {
        if (flag) {//③
            int i = a;//④
        }
    }
}
```

2、volatile变量规则，对于volatile修饰的变量的写操作，一定happen-before后续对于volatile变量的读操作；根据volatile规则，上述例子：② happens-before ③

3、传递性规则，如果① happens-before ② ； ③ happens-before ④；那么根据传递性规则 ① happens-before ④

4、start规则，如果线程A执行操作ThreadB.start()，那么线程A的ThreadB.start()操作happens-before于线程B中的任意操作

5、join规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回

6、监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁

```
synchronized (this){//加锁
   this.a = 10;
}//解锁
```

### J.U.C简介

Java.util.concurrent 是在并发编程中比较常用的工具类，里面包含很多用来在并发场景中使用的组件。比如线程池、阻塞队列、计时器、同步器、并发集合等等。

#### Lock

Lock在J.U.C中是最核心的组件，里面绝大部分的组件都有用到Lock，所以通过Lock作为切入点会让后面学习并发工具更好理解。

##### Lock 简介

在Lock接口出现之前，Java中的应用程序对于多线程的并发安全处理只能基于synchronized关键字来解决，但是synchronized在有些场景中会存在一些短板，不适合所有的并发场景。但是在Java5以后，Lock的出现可以解决synchronized在某些场景中的短板，它比synchronized更加灵活。

##### Lock的实现

Lock本质上是一个接口，它定义了释放锁和获得锁的抽象方法，定义成接口就意味着它定义了锁的一个标准规范，也同时意味着锁的不通实现。实现Lock接口的类有很多，以下为几个常用的锁实现：

**ReentrantLock：**表示重入锁，它是唯一一个实现了Lock接口的类。重入锁指的是线程在获得锁之后，再次获取该锁不需要阻塞，而是直接关联一次计数器增加冲入次数；

**ReentrantReadWriteLock：**重入读写锁，它实现了ReadWriteLock接口，在这个类中维护了两个锁，一个是ReadLock，一个WriteLock，他们都分别实现了Lock接口。读写锁是一种适合读多写少的场景下解决线程安全问题的工具，基本上原则是：**读读不互斥、读写互斥、写写互斥**。也就是说设计到影响数据变化的操作都会存在互斥。

**StampedLock：**stampedLock是JDK8引入，新的锁机制，可以简单认为是读写锁的一个改进版，读写锁虽然通过分离读和写的功能使得读和读之间可以完全并发，但是读和写是有冲突的，如果大量的读线程存在，可能会引起写线程的饥饿。stampedLock是一种乐观的读策略，使得乐观锁完全不会阻塞写线程。

##### Lock的类关系图

Lock有很多的锁的实现，但是直观的实现是ReentrantLock重入锁

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/Lock类图.png)

##### ReentrantLock 重入锁

重入锁，指支持重新进入的锁，也就是说，如果当前线程t1通过调用lock方法获取了锁之后，再次调用lock，是不会阻塞去获取锁的，直接增加重试次数就行了。

###### 重入锁的设计目的：

重入锁的设计目的就是为了避免线程的死锁。

比如调用demo方法获得了当前的对象锁，然后在这个方法中再去调用demo2，demo2中的存在同一实例锁，这个时候当前线程会因为无法获得demo2的对象锁而阻塞，就会产生死锁。

###### synchronized 重入特性案例

```java
public class ReentrantLockDemo {
    public synchronized void demo(){
        System.out.println("begin:demo");
        demo2();
    }

    public void demo2(){
        System.out.println("begin:demo1");
        synchronized (this){

        }
    }
    public static void main(String[] args) {
        ReentrantLockDemo reentrantLockDemo = new ReentrantLockDemo();
        new Thread(reentrantLockDemo::demo).start();
    }
}
```

###### ReentrantLock的使用

```
public class AtomicDemo {
    private static int count = 0;

    static Lock lock = new ReentrantLock();

    public static void inr() {
        lock.lock();
        try {
            Thread.sleep(1);
        } catch (Exception e) {
            e.printStackTrace();
        }
        count++;
        lock.unlock();
    }

    public static void main(String[] args) throws InterruptedException {
        for (int i = 0; i < 1000; i++) {
            new Thread(AtomicDemo::inr).start();
        }
        Thread.sleep(3000);
        System.out.println("result:" + count);
    }
}
```

###### ReentrantReadWriteLock使用

```java
public class HashMapDemo {
    static Map<String,Object> cacheMap = new HashMap<>();
    static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
    static Lock read = rwl.readLock();
    static Lock write = rwl.writeLock();

    public static Object get(String key){
        System.out.println("开始读数据");
        read.lock();
        try {
            return cacheMap.get(key);
        }finally {
            read.unlock();
        }
    }

    public static Object put(String key,Object value){
        System.out.println("开始写数据");
        write.lock();
        try {
            return cacheMap.put(key,value);
        }finally {
            write.unlock();
        }
    }

    public static void main(String[] args) {
        put("a",1);
        System.out.println(get("a"));
    }
}
```

##### ReentrantLock的实现原理

我们知道锁的基本原理是，基于将多线程并行任务通过某一种机制实现线程的串行执行，从而达到线程安全性的目的。在synchronized中，乐观锁和自旋锁优化了synchronized的加锁开销，同时在重量级锁阶段，通过线程的阻塞以及唤醒来达到线程竞争和同步的目的。那么在ReentrantLock中，在多线程竞争重入锁时，竞争失败的线程是如何实现阻塞以及被唤醒的呢？

##### 什么是AQS？

在Lock中，用到了一个同步队列AQS，全称AbstractQueueSynchronized，它是一个同步工具也是Lock用来实现线程同步的核心组件。

##### AQS的两种功能

从使用层面来说，AQS的功能分为两种：独占和共享

**独占锁：**每次只能有一个线程持有锁，比如前面说的ReentrantLock就是以独占方式实现的互斥锁；

**共享锁：**允许多个线程同时获取锁，并发访问共享资源，比如ReentrantReadWriteLock

##### AQS的内部实现：

AQS队列内部维护的是一个FIFO的双向链表，这种结构的特点是每个数据结构都有两个指针，分别指向后继节点和前驱节点。每个Node其实是由线程封装，当线程争抢锁失败后会封装成node加入到AQS队列中去；当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点（线程）。

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/AQS原理图.png)

Node的组成

```java
static final class Node {
    /** Marker to indicate a node is waiting in shared mode */
    static final Node SHARED = new Node();
    /** Marker to indicate a node is waiting in exclusive mode */
    static final Node EXCLUSIVE = null;

    /** waitStatus value to indicate thread has cancelled */
    static final int CANCELLED =  1;
    /** waitStatus value to indicate successor's thread needs unparking */
    static final int SIGNAL    = -1;
    /** waitStatus value to indicate thread is waiting on condition */
    static final int CONDITION = -2;
    /**
     * waitStatus value to indicate the next acquireShared should
     * unconditionally propagate
     */
    static final int PROPAGATE = -3;
    volatile int waitStatus;
    volatile Node prev;//前驱节点
    volatile Node next;//后继节点
    volatile Thread thread;//当前线程
    Node nextWaiter;//存储在condition队列中的后继节点
    //是否为共享锁
    final boolean isShared() {
        return nextWaiter == SHARED;
    }
    final Node predecessor() throws NullPointerException {
        Node p = prev;
        if (p == null)
            throw new NullPointerException();
        else
            return p;
    }

    Node() {    // Used to establish initial head or SHARED marker
    }
    //将线程构造成一个node，添加到等待队列
    Node(Thread thread, Node mode) {     // Used by addWaiter
        this.nextWaiter = mode;
        this.thread = thread;
    }
    //这个方法会在condition队列中使用
    Node(Thread thread, int waitStatus) { // Used by Condition
        this.waitStatus = waitStatus;
        this.thread = thread;
    }
}
```

##### 分析释放锁以及添加线程对于队列的变化：

当出现竞争以及释放锁的时候，AQS同步队列中的节点会发生变化，如下图：

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/AQS添加线程.png)

**这里会涉及到两个变化**

1、新的线程封装成Node节点追加到同步队列中，设置prev节点以及修改当前节点的前驱节点的next节点指向自己

2、通过CAS讲tail重新指向新的尾部节点

head节点表示获取锁成功的节点，当头结点在释放同步状态是，会唤醒后继节点，如果后继节点获得锁成功，会把自己设置为头节点，节点的变化过程如下：

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/AQS获取锁.png)

**这里也是涉及到两个变化**

1、修改head节点指向下一个获取锁的节点

2、新的获得锁的节点，将prev的指针指向null

**⚠️注意：**

设置head节点不需要用CAS，原因是设置head节点是由获得锁的线程来完成的，而同步锁只能由一个线程获得，所以不需要CAS保证，只需要把head节点设置为原首节点，并且断开原head节点的next引用即可。

##### ReentrantLock的源码分析：

以ReentrantLock作为切入点，来看看在这个场景中是如何使用AQS来实现线程的同步的

##### ReentrantLock的时序图：

调用ReentrantLock中的lock()方法，源码的调用过程如下：

**公平锁源码：**

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/ReentrantLock#FairSync源码分析.png)

**非公平锁源码时序图**

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/ReentrantLock#NonfairSync源码分析.png)

Sync有两个具体的实现类，分别是：

1、NofairSync：表示可以存在抢占锁的功能，也就是说不管当前队列上是否存在其他线程等待，新线程都有机会抢占锁

2、FairSync：表示所有线程严格按照FIFO来获取锁

以非公平锁为例，来看看lock中的实现：

1、非公平锁和公平锁最大的区别在于，非公平锁中不管有没有线程排队，我先上来CAS去抢占一下

2、CAS成功，就表示成功获得了锁

3、CAS失败，调用acquire(1)走锁竞争逻辑

```java
			final void lock() {
            if (compareAndSetState(0, 1))
                setExclusiveOwnerThread(Thread.currentThread());
            else
                acquire(1);
        }
```

**CAS的实现原理**

```java
		protected final boolean compareAndSetState(int expect, int update) {
        // See below for intrinsics setup to support this
        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
    }
```

通过CAS乐观锁的方式来做比较并替换，这段代码的意思是，如果当前内存中的state的值和预期值expect相等，则替换为update。更新成功返回true，否则返回false。这个操作是原子的，不会出现线程安全问题，这里面涉及到Unsafe这个类的操作，以及涉及到state这个属性的意义。

**state**是AQS中的一个属性，它在不同的实现中所表达的含义不一样，对于重入锁的实现来说，表示一个同步状态。它有两个含义的表示：

1、当state=0时，表示无锁状态；

2、当state>0时，表示已经有线程获得了锁，也就是state=1，但是因为ReentrantLock允许重入，所以同一个线程多次获得同步锁的时候，state会递增，比如重入5次，那么state=5.而在释放锁的时候，同样需要释放5次直到state=0，其他线程才有资格获得锁

**Unsafe类**

Unsafe是在sun.misc包下，不属于Java标准，但是很多Java的基础类库，包括一些被广泛使用的高性能开发库都是基于Unsafe类开发的，比如Netty、Hadoop、Kafka等；

Unsafe可以认为是Java中留下的后门，提供了一些低层次操作，如直接内存访问、线程的挂起和恢复、CAS、线程同步、内存屏障；

**stateOffset**

一个Java对象可以看成是一段内存，每个字段都得按照一定的顺序放在这段内存里，通过这个方法可以准确告诉你某个字段相对于对象的起始内存地址的字节偏移。用于在后面的compareAndSwapInt中，去根据偏移量找到对象在内存中的具体位置，所以stateOffset表示state这个字段在AQS类的内存中相对于该类首地址的偏移量

**AQS.accquire**

acquire是AQS中的方法，如果CAS操作未能成功，说明state已经不为0，此时继续acquire(1)操作

这个方法的主要逻辑是：

1、通过tryAcquire尝试获取独占锁，如果成功返回true，失败返回false

2、如果tryAcquire失败，则会通过addWaiter方法将当前线程封装成Node添加到AQS队列尾部

3、acquireQueued，将Node作为参数，通过自旋去尝试获取锁。

```java
		public final void acquire(int arg) {
        if (!tryAcquire(arg) &&
            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
            selfInterrupt();
    }
```

**NonfairSync.tryAcquire**

这个方法的作用是尝试获取锁，如果成功返回true，不成功返回false，他是一个模板方法，通过子类来实现逻辑

```java
protected final boolean tryAcquire(int acquires) {
   return nonfairTryAcquire(acquires);
}
```

**ReentrantLock.nofairTryAcquire**

1、获取当前线程，判断当前的锁的状态

2、如果state=0表示当前是无锁状态，通过CAS更新state状态的值

3、当前线程是属于重入，则增加重入次数

```java
final boolean nonfairTryAcquire(int acquires) {
            final Thread current = Thread.currentThread();//获取当前执行的线程
            int c = getState();//获取state的值
            if (c == 0) {//表示无锁状态
            		//尝试获取锁
                if (compareAndSetState(0, acquires)) {
                		//保存当前获得锁的线程，下次再来的时候不需要再尝试竞争锁
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            //如果同一个线程来获得锁，直接增加重入次数
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0) // overflow
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
```

**AQS.addWaiter**

当tryAcquire方法获取锁失败以后，则会先调用addWaiter将当前线程封装成Node，入参mode表示当前节点的状态，传递的参数是Node.EXCLUSIVE,表示独占状态。意味着重入锁用到了AQS的独占锁功能

1、将当前线程封装成Node

2、当前链表中的tail节点是否为空，如果不为空，则通过CAS操作把当前线程的node添加到AQS队列

3、如果为空或者CAS失败，掉一共enq将及节点添加到AQS队列

```java
private Node addWaiter(Node mode) {
  			//把当前线程封装为node
        Node node = new Node(Thread.currentThread(), mode);
        // tail是AQS中表示队列队尾属性，默认为null
        Node pred = tail;
  			//tail不为空的情况下，说明队列中存在节点
        if (pred != null) {
          	//把当前线程的Node的pre指向tail
            node.prev = pred;
          	//通过CAS把node加入到AQS队列，也就是设置为tail
            if (compareAndSetTail(pred, node)) {
              	//设置成功以后，把原tail节点的next指向当前node
                pred.next = node;
                return node;
            }
        }
  			//tail=null，把node添加到同步队列
        enq(node);
        return node;
    }
```

**enq**

enq就是通过自旋操作把当前节点加入到队列中

```java
private Node enq(final Node node) {
        for (;;) {
            Node t = tail;
            if (t == null) { // Must initialize
                if (compareAndSetHead(new Node()))
                    tail = head;
            } else {
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                    t.next = node;
                    return t;
                }
            }
        }
    }
```

**AQS.acquireQueued**

通过addWaiter方法把线程添加到链表后，会接着把Node作为参数传递给acquireQueued方法，去竞争锁

1、获取当前节点的prev节点

2、如果pre节点为head节点，那么它就有资格去争抢锁，调用tryAcquire抢占锁

3、抢占锁成功以后，把获得锁的节点设置为head，并且移除原来的初始化head节点

4、如果获得锁失败，则根据waitStatus决定是否需要挂起线程

5、最后，通过cancelAcquire取消获得锁的操作

```java
final boolean acquireQueued(final Node node, int arg) {
        boolean failed = true;
        try {
            boolean interrupted = false;
            for (;;) {
            		//获取当前节点的prev节点
                final Node p = node.predecessor();
                //如果pre节点为head节点，那么它就有资格去争抢锁
                if (p == head && tryAcquire(arg)) {
                		//获取锁成功了，也就是说线程1已经释放锁了，然后设置head为线程2获得执行权限
                    setHead(node);
                    //把原head节点从链表中移除
                    p.next = null; 
                    failed = false;
                    return interrupted;
                }
                //线程1可能还没有释放锁，使得线程2在执行tryAcquire时会返回false
                if (shouldParkAfterFailedAcquire(p, node) &&
                    parkAndCheckInterrupt())
                    //并且返回当前线程在等待过程中有没有中断过
                    interrupted = true;
            }
        } finally {
            if (failed)
                cancelAcquire(node);
        }
    }
```

**shouldParkAfterFailedAcquire**

如果线程1的锁还没有释放的情况下，线程2和线程3来争抢锁肯定是会失败，那么失败以后会调用shouldParkAfterFailedAcquire方法

Node中waitStatus有五种状态，分别是：CANCELLED(1)、SIGNAL(-1)、CONDITION(-2)、PROPAGATE(-3),默认状态为0

CANCELLED：在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的节点，其节点的waitStatus为CANCELLED，即结束状态，进入该状态后的节点将不会再变化

SIGNAL：只要前置节点释放锁，就会通知标识符为SIGNAL状态的后继节点的线程

CONDITION：和Condition有关系，后续会说

PROPAGATE：共享模式下，PROPAGATE状态的线程处于可运行状态

这个方法的主要作用是，通过Node的状态来判断，线程1竞争锁失败以后是否应该被挂起。

1、如果线程1的pred节点状态为SIGNAL，那就表示可以放心挂起当前线程

2、通过循环扫描链表把CANCELLED状态的节点移除

3、修改pred节点的状态为SIGNAL，返回false

返回false时，也就是不需要挂起，返回true，则需要调用parkAndCheckInterrupt挂起当前线程

```java
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
        int ws = pred.waitStatus;
        //如果前置节点为SIGNAL，意味着只需要等待其他前置节点的线程被释放
        if (ws == Node.SIGNAL)
            //意味着可以直接放心的挂起线程
            return true;
        //ws大于0，意味着prev节点取消了排队，直接移除这个节点    
        if (ws > 0) {
            do {
                node.prev = pred = pred.prev;
            } while (pred.waitStatus > 0);
            pred.next = node;
        } else {
            //利用CAS设置prev节点的状态为SIGNAL
            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
        }
        return false;
    }
```

**parkAndCheckInterrupt**

1、使用LockSupport.park(this);挂起当前线程变成WATING状态

2、Thread.interrupted();返回当前线程是否被其他线程触发过中断请求，也就是thread.interrupt();如果有触发过中断请求，那么方法会返回当前的中断标志true。

```java
private final boolean parkAndCheckInterrupt() {
        LockSupport.park(this);
        return Thread.interrupted();
    }
```

**LockSupport**

LockSupport类是Java6引入的一个类，提供了基本的线程同步原语。LockSupport实际上是调用了Unsafe类里的函数，归结到Unsafe里，只有两个函数

```java
public native void unpark(Object var1);

public native void park(boolean var1, long var2);

```

unpark函数为线程提供“许可”(permit)，线程调用park函数则等待“许可”。这个有点像信号量，但是这个“许可”是不能叠加的，“许可”是一次性的。permit相当于0/1的开关，默认是0，调用一次unpark就变成1，调用一次park会消费permit，又会变成0.如果再调用一次park会阻塞，因为permit已经是0了。直到permit变成1，这是调用unpark会把permit设置为1，每个线程都有一个相关的permit，permit最多只有一个，重复调用unpark不会累积。

##### 锁的释放流程

ReentrantLock.unlock();在unlock中，会调用release方法来释放锁：

```java
public final boolean release(int arg) {
  			//释放锁成功
        if (tryRelease(arg)) {
          	//获取到AQS中的head节点
            Node h = head;
						//如果head节点不为空并且状态不等于0
            if (h != null && h.waitStatus != 0)
              	//则唤醒后续节点
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
```

这个方法可以认为是一个设置锁状态的操作，通过将state状态减掉传入的参数值，如果结果状态为0，就将排它锁的Owner设置为null，以使得其他的线程有机会进行执行。在排它锁中，加锁的时候状态会增加1，在解锁的时候减掉1，同一个锁，再重入后，可能会被叠加到2、3、4，只有unlock()的次数与lock()的次数对应才会将Owner线程设置为空，而且也只有这种情况下才会返回true。

```
protected final boolean tryRelease(int releases) {
            int c = getState() - releases;
            if (Thread.currentThread() != getExclusiveOwnerThread())
                throw new IllegalMonitorStateException();
            boolean free = false;
            if (c == 0) {
                free = true;
                setExclusiveOwnerThread(null);
            }
            setState(c);
            return free;
            }
```

**unparkSuccessor**

```java
private void unparkSuccessor(Node node) {
        
        int ws = node.waitStatus;
        if (ws < 0)
        		//设置head节点状态为0
            compareAndSetWaitStatus(node, ws, 0);
				//得到head节点的下一个节点
        Node s = node.next;
        //如果下一个节点为null或者status>0表示cancelled状态；
        //通过从尾部节点开始扫描，找到距离head最近的一个status<=0的节点
        if (s == null || s.waitStatus > 0) {
            s = null;
            for (Node t = tail; t != null && t != node; t = t.prev)
                if (t.waitStatus <= 0)
                    s = t;
        }
        if (s != null)//next节点不为空，直接唤醒这个线程即可
            LockSupport.unpark(s.thread);
    }
```

**为什么在释放锁的时候是从tail进行扫描？**

首先要知道一个新节点是如何加入到链表中的：

1、将新的节点的prev指向tail

2、通过cas将tail设置为新的节点，因为cas是原子操作所以能够保证线程安全性

3、t.next = node；设置原tail的next节点指向新的节点

![images](https://github.com/GoldWater16/GoldWater/blob/master/precipitation/images/多线程并发安全原理图片/AQS添加节点过程.png)

在CAS操作之后，t.next=node操作之前，存在其他线程调用unlock方法从head开始往后遍历，由于t.next=node还没执行意味着链表的关系还没有建立完整。就会导致遍历到t节点的时候被中断。所以从后往前遍历，一定不会存在这个问题。

















































